{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/your-repo/cscg_torch/blob/main/examples/colab_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "title"
   },
   "source": [
    "# CSCG PyTorch Demo - Google Colab\n",
    "\n",
    "This notebook demonstrates the GPU-optimized CSCG PyTorch implementation in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "setup-header"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.2' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "!pip install torch>=2.1.0 numpy>=1.24 matplotlib>=3.7 tqdm>=4.65 scipy>=1.10\n",
    "\n",
    "# Clone repository (replace with actual repo URL)\n",
    "!git clone https://github.com/your-repo/cscg_torch.git\n",
    "\n",
    "# Add to Python path\n",
    "import sys\n",
    "sys.path.append('/content/cscg_torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check-gpu"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"No GPU available - using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "basic-usage"
   },
   "source": [
    "## Basic Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "import-cscg"
   },
   "outputs": [],
   "source": [
    "from cscg_torch import CHMM_torch\n",
    "\n",
    "# Generate synthetic data\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Define model structure\n",
    "n_clones = torch.tensor([3, 4, 2, 3], dtype=torch.int64)  # clones per observation\n",
    "sequence_length = 200\n",
    "\n",
    "# Generate random sequences\n",
    "x = torch.randint(0, len(n_clones), (sequence_length,), dtype=torch.int64)\n",
    "a = torch.randint(0, 3, (sequence_length-1,), dtype=torch.int64)  # 3 actions\n",
    "\n",
    "print(f\"Observation sequence length: {len(x)}\")\n",
    "print(f\"Action sequence length: {len(a)}\")\n",
    "print(f\"Number of observation types: {len(n_clones)}\")\n",
    "print(f\"Total clone states: {n_clones.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "create-model"
   },
   "outputs": [],
   "source": [
    "# Create CHMM model\n",
    "model = CHMM_torch(\n",
    "    n_clones=n_clones,\n",
    "    x=x,\n",
    "    a=a,\n",
    "    pseudocount=1e-6,\n",
    "    dtype=torch.float32,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"Model created successfully!\")\n",
    "print(f\"Model device: {model.device}\")\n",
    "print(f\"Transition matrix shape: {model.T.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "training"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "em-training"
   },
   "outputs": [],
   "source": [
    "# EM Training\n",
    "print(\"Starting EM training...\")\n",
    "convergence_em = model.learn_em_T(x, a, n_iter=50, term_early=True)\n",
    "\n",
    "print(f\"\\nEM Training completed!\")\n",
    "print(f\"Final BPS: {convergence_em[-1]:.4f}\")\n",
    "print(f\"Converged in {len(convergence_em)} iterations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "plot-convergence"
   },
   "outputs": [],
   "source": [
    "# Plot convergence\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(convergence_em, 'b-', linewidth=2, label='EM Training')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Bits per Step (BPS)')\n",
    "plt.title('CHMM Training Convergence')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Improvement: {convergence_em[0] - convergence_em[-1]:.4f} BPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "inference"
   },
   "source": [
    "## Inference and Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "likelihood"
   },
   "outputs": [],
   "source": [
    "# Compute likelihood\n",
    "bps_total = model.bps(x, a, reduce=True)\n",
    "bps_per_step = model.bps(x, a, reduce=False)\n",
    "\n",
    "print(f\"Total BPS: {bps_total:.4f}\")\n",
    "print(f\"Average BPS: {bps_per_step.mean():.4f}\")\n",
    "print(f\"BPS std: {bps_per_step.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "decoding"
   },
   "outputs": [],
   "source": [
    "# MAP decoding\n",
    "map_likelihood, map_states = model.decode(x, a)\n",
    "\n",
    "print(f\"MAP log-likelihood: {-map_likelihood:.4f}\")\n",
    "print(f\"MAP states shape: {map_states.shape}\")\n",
    "print(f\"First 10 MAP states: {map_states[:10]}\")\n",
    "\n",
    "# Viterbi likelihood\n",
    "viterbi_bps = model.bpsV(x, a)\n",
    "print(f\"Viterbi BPS: {viterbi_bps:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emissions"
   },
   "source": [
    "## Emission Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emission-training"
   },
   "outputs": [],
   "source": [
    "# Learn emission matrix\n",
    "print(\"Learning emission matrix...\")\n",
    "convergence_e, E = model.learn_em_E(x, a, n_iter=30)\n",
    "\n",
    "print(f\"Emission learning completed!\")\n",
    "print(f\"Final emission BPS: {convergence_e[-1]:.4f}\")\n",
    "print(f\"Emission matrix shape: {E.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emission-inference"
   },
   "outputs": [],
   "source": [
    "# Inference with learned emissions\n",
    "bps_with_emissions = model.bpsE(E, x, a)\n",
    "map_lik_e, map_states_e = model.decodeE(E, x, a)\n",
    "\n",
    "print(f\"BPS with emissions: {bps_with_emissions:.4f}\")\n",
    "print(f\"MAP likelihood with emissions: {-map_lik_e:.4f}\")\n",
    "\n",
    "# Compare emission matrix\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.imshow(E.cpu().numpy(), aspect='auto', cmap='viridis')\n",
    "plt.colorbar(label='Emission Probability')\n",
    "plt.xlabel('Observation Type')\n",
    "plt.ylabel('Clone State')\n",
    "plt.title('Learned Emission Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "generation"
   },
   "source": [
    "## Sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sampling"
   },
   "outputs": [],
   "source": [
    "# Generate sequences from learned model\n",
    "sample_length = 50\n",
    "sample_x, sample_a = model.sample(sample_length)\n",
    "\n",
    "print(f\"Generated sequence length: {len(sample_x)}\")\n",
    "print(f\"Sample observations: {sample_x[:20]}\")\n",
    "print(f\"Sample actions: {sample_a[:20]}\")\n",
    "\n",
    "# Conditional generation\n",
    "conditional_seq = model.sample_sym(sym=0, length=20)\n",
    "print(f\"Conditional sequence starting with 0: {conditional_seq}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "performance"
   },
   "source": [
    "## Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "benchmark"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Benchmark GPU vs CPU (if both available)\n",
    "if torch.cuda.is_available():\n",
    "    # GPU timing\n",
    "    model_gpu = CHMM_torch(n_clones, x, a, dtype=torch.float32)\n",
    "    \n",
    "    torch.cuda.synchronize()\n",
    "    start_time = time.time()\n",
    "    _ = model_gpu.learn_em_T(x, a, n_iter=10)\n",
    "    torch.cuda.synchronize()\n",
    "    gpu_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"GPU training time (10 iterations): {gpu_time:.2f}s\")\n",
    "    \n",
    "    # Memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        memory_used = torch.cuda.max_memory_allocated() / 1e6\n",
    "        print(f\"Peak GPU memory usage: {memory_used:.1f} MB\")\n",
    "else:\n",
    "    print(\"GPU not available for benchmarking\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary"
   },
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Setup**: Installing dependencies and checking GPU availability\n",
    "2. **Model Creation**: Building CHMM with clone states\n",
    "3. **Training**: EM algorithm for transition learning\n",
    "4. **Inference**: Likelihood computation and MAP decoding\n",
    "5. **Emissions**: Learning and using emission matrices\n",
    "6. **Generation**: Sampling sequences from trained models\n",
    "7. **Performance**: GPU acceleration benefits\n",
    "\n",
    "The CSCG PyTorch implementation provides efficient GPU-accelerated training and inference for Hidden Markov Models with compositional structure."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
