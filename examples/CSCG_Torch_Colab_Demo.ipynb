{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cscg_intro"
      },
      "source": [
        "# üöÄ CSCG-Torch\n",
        "\n",
        "This notebook demonstrates how to use CSCG-Torch for GPU-accelerated sequence generation and CHMM training.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/your-repo/cscg-torch/blob/main/examples/CSCG_Torch_Colab_Demo.ipynb)\n",
        "\n",
        "## Features\n",
        "- üöÄ GPU-accelerated sequence generation\n",
        "- üß† V100/A100 optimized Tensor Cores\n",
        "- ‚ö° Fast CHMM training with mixed precision\n",
        "- üìä Easy visualization and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "installation"
      },
      "source": [
        "## üì¶ Installation\n",
        "\n",
        "First, let's install CSCG-Torch and check our GPU setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install_cscg"
      },
      "outputs": [],
      "source": [
        "# Install CSCG-Torch\n",
        "!git clone https://github.com/your-repo/cscg-torch.git\n",
        "%cd cscg-torch\n",
        "!pip install -e .\n",
        "\n",
        "# Check installation\n",
        "import cscg_torch\n",
        "print(f\"‚úÖ CSCG-Torch v{cscg_torch.__version__} installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpu_check"
      },
      "source": [
        "## üîç GPU Detection and Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_gpu"
      },
      "outputs": [],
      "source": [
        "# Check GPU information\n",
        "device = cscg_torch.detect_optimal_device()\n",
        "gpu_info = cscg_torch.get_gpu_info(device)\n",
        "\n",
        "print(f\"üñ•Ô∏è  Device: {gpu_info['name']}\")\n",
        "print(f\"üíæ Memory: {gpu_info.get('memory_gb', 'N/A')} GB\")\n",
        "print(f\"‚ö° Optimizations: {', '.join(gpu_info['optimizations'])}\")\n",
        "\n",
        "# Get optimal settings for this GPU\n",
        "gpu_settings = cscg_torch.optimize_for_gpu(device)\n",
        "print(f\"\\nüöÄ Optimal chunk size: {gpu_settings['chunk_size']:,}\")\n",
        "print(f\"üß† Tensor Cores: {gpu_settings['tensor_cores']}\")\n",
        "print(f\"üî¢ Mixed Precision: {gpu_settings['mixed_precision']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "benchmark"
      },
      "source": [
        "## üìä GPU Performance Benchmark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run_benchmark"
      },
      "outputs": [],
      "source": [
        "# Benchmark GPU performance\n",
        "print(\"üèÉ‚Äç‚ôÇÔ∏è Running GPU benchmark...\")\n",
        "benchmark_results = cscg_torch.benchmark_device(device)\n",
        "\n",
        "print(f\"‚ö° Performance: {benchmark_results['gflops']:.1f} GFLOPS\")\n",
        "if 'memory_bandwidth_gb_s' in benchmark_results:\n",
        "    print(f\"üíæ Memory Bandwidth: {benchmark_results['memory_bandwidth_gb_s']:.1f} GB/s\")\n",
        "\n",
        "# Memory information\n",
        "mem_info = cscg_torch.get_memory_info(device)\n",
        "print(f\"\\nüíæ Available Memory: {mem_info['available_gb']:.1f} GB\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "load_data"
      },
      "source": [
        "## üè† Load Room Data and Create Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "setup_environment"
      },
      "outputs": [],
      "source": [
        "# Load pre-generated room data\n",
        "print(\"üè† Loading room data...\")\n",
        "available_rooms = cscg_torch.get_available_rooms()\n",
        "print(f\"Available rooms: {list(available_rooms.keys())}\")\n",
        "\n",
        "# Load a 20x20 room for demonstration\n",
        "room_data = cscg_torch.load_room_data(\"room_20x20\")\n",
        "print(f\"Room shape: {room_data.shape}\")\n",
        "\n",
        "# Get room information\n",
        "room_info = cscg_torch.room_info(room_data)\n",
        "print(f\"Total cells: {room_info['total_cells']}\")\n",
        "print(f\"Free cells: {room_info['free_cells']}\")\n",
        "print(f\"Unique observations: {room_info['unique_observations']}\")\n",
        "\n",
        "# Create room adapter\n",
        "adapter = cscg_torch.create_room_adapter(room_data, adapter_type=\"torch\", seed=42)\n",
        "print(\"‚úÖ Room adapter created successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize_room"
      },
      "source": [
        "## üé® Visualize Room Layout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_room"
      },
      "outputs": [],
      "source": [
        "# Plot the room layout\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig = cscg_torch.plot_room_layout(\n",
        "    room_data, \n",
        "    title=\"20x20 Room Navigation Environment\",\n",
        "    colormap='tab20'\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "print(\"üé® Room layout visualization complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generate_sequences"
      },
      "source": [
        "## ‚ö° GPU-Accelerated Sequence Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fast_generation"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# Test different sequence lengths to see GPU acceleration\n",
        "test_lengths = [10_000, 50_000, 100_000]\n",
        "generation_times = []\n",
        "generation_rates = []\n",
        "\n",
        "print(\"üöÄ Testing GPU sequence generation performance...\\n\")\n",
        "\n",
        "for seq_len in test_lengths:\n",
        "    print(f\"Generating {seq_len:,} steps...\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    x_seq, a_seq = adapter.generate_sequence_gpu(seq_len, device=device)\n",
        "    end_time = time.time()\n",
        "    \n",
        "    generation_time = end_time - start_time\n",
        "    rate = seq_len / generation_time\n",
        "    \n",
        "    generation_times.append(generation_time)\n",
        "    generation_rates.append(rate)\n",
        "    \n",
        "    print(f\"  ‚úÖ Generated in {generation_time:.2f}s ({rate:,.0f} steps/sec)\")\n",
        "    print(f\"  üìä Obs range: [{x_seq.min()}, {x_seq.max()}], Action range: [{a_seq.min()}, {a_seq.max()}]\\n\")\n",
        "\n",
        "# Use the largest sequence for training\n",
        "print(f\"Using {len(x_seq):,} step sequence for CHMM training...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "performance_plot"
      },
      "source": [
        "## üìà GPU Performance Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_performance"
      },
      "outputs": [],
      "source": [
        "# Plot GPU performance scaling\n",
        "fig = cscg_torch.plot_gpu_performance(\n",
        "    test_lengths, \n",
        "    generation_times,\n",
        "    device_name=gpu_info['name']\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìä Average generation rate: {sum(generation_rates)/len(generation_rates):,.0f} steps/second\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sequence_analysis"
      },
      "source": [
        "## üîç Sequence Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "analyze_sequences"
      },
      "outputs": [],
      "source": [
        "# Analyze the generated sequences\n",
        "fig = cscg_torch.plot_sequence_statistics(x_seq, a_seq)\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìà Sequence statistics plotted for {len(x_seq):,} steps\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train_model"
      },
      "source": [
        "## üß† CHMM Training with GPU Optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train_chmm"
      },
      "outputs": [],
      "source": [
        "# Setup model parameters\n",
        "n_clones_per_obs = 150  # Adjust based on GPU memory\n",
        "n_clones = cscg_torch.get_room_n_clones(n_clones_per_obs=n_clones_per_obs, device=device)\n",
        "\n",
        "print(f\"üß† Training CHMM with {n_clones.sum().item()} total states...\")\n",
        "print(f\"üìä Sequence length: {len(x_seq):,} steps\")\n",
        "print(f\"üîß Using {gpu_info['name']} with {', '.join(gpu_info['optimizations'])}\")\n",
        "\n",
        "# Train the model with GPU optimization\n",
        "start_time = time.time()\n",
        "\n",
        "model, progression = cscg_torch.train_chmm(\n",
        "    n_clones=n_clones,\n",
        "    x=x_seq,\n",
        "    a=a_seq,\n",
        "    device=device,\n",
        "    method='em_T',\n",
        "    n_iter=50,\n",
        "    enable_mixed_precision=gpu_settings['mixed_precision'],\n",
        "    learn_E=True,\n",
        "    early_stopping=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "training_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\n‚úÖ Training completed in {training_time:.2f} seconds!\")\n",
        "print(f\"üìà Final BPS: {progression[-1]:.4f}\")\n",
        "print(f\"üìä Total improvement: {progression[0] - progression[-1]:.4f} BPS\")\n",
        "print(f\"üéØ Convergence: {len(progression)} iterations\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize_training"
      },
      "source": [
        "## üìä Training Results Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plot_training"
      },
      "outputs": [],
      "source": [
        "# Plot training progression\n",
        "fig = cscg_torch.plot_training_progression(\n",
        "    progression,\n",
        "    title=f\"CHMM Training on {gpu_info['name']}\",\n",
        "    show_improvement=True\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "print(f\"üìà Training progression plotted ({len(progression)} iterations)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "model_evaluation"
      },
      "source": [
        "## üéØ Model Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate_model"
      },
      "outputs": [],
      "source": [
        "# Evaluate model performance\n",
        "import torch\n",
        "\n",
        "# Convert sequences to tensors for evaluation\n",
        "x_tensor = torch.tensor(x_seq, device=device, dtype=torch.int64)\n",
        "a_tensor = torch.tensor(a_seq, device=device, dtype=torch.int64)\n",
        "\n",
        "# Calculate bits per step\n",
        "final_bps = model.bps(x_tensor, a_tensor, reduce=True)\n",
        "print(f\"üéØ Final Bits Per Step: {final_bps:.4f}\")\n",
        "\n",
        "# Decode optimal state sequence\n",
        "print(\"üîç Decoding optimal state sequence...\")\n",
        "neg_log_lik, states = model.decode(x_tensor, a_tensor)\n",
        "print(f\"üìä MAP negative log-likelihood: {neg_log_lik:.4f}\")\n",
        "print(f\"üß† Decoded {len(states)} states\")\n",
        "\n",
        "# Model statistics\n",
        "unique_states = torch.unique(states)\n",
        "print(f\"\\nüìà Model Statistics:\")\n",
        "print(f\"  ‚Ä¢ Total possible states: {n_clones.sum().item()}\")\n",
        "print(f\"  ‚Ä¢ Unique states used: {len(unique_states)}\")\n",
        "print(f\"  ‚Ä¢ State utilization: {len(unique_states)/n_clones.sum().item()*100:.1f}%\")\n",
        "print(f\"  ‚Ä¢ Training efficiency: {(progression[0]-progression[-1])/progression[0]*100:.1f}% improvement\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "memory_usage"
      },
      "source": [
        "## üíæ Memory Usage Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "check_memory"
      },
      "outputs": [],
      "source": [
        "# Check final memory usage\n",
        "final_mem_info = cscg_torch.get_memory_info(device)\n",
        "\n",
        "print(\"üíæ Final Memory Usage:\")\n",
        "print(f\"  ‚Ä¢ Used: {final_mem_info['used_gb']:.1f} GB\")\n",
        "print(f\"  ‚Ä¢ Available: {final_mem_info['available_gb']:.1f} GB\")\n",
        "print(f\"  ‚Ä¢ Cached: {final_mem_info['cached_gb']:.1f} GB\")\n",
        "\n",
        "# Performance summary\n",
        "print(f\"\\nüöÄ Performance Summary:\")\n",
        "print(f\"  ‚Ä¢ GPU: {gpu_info['name']}\")\n",
        "print(f\"  ‚Ä¢ Sequence generation: {generation_rates[-1]:,.0f} steps/sec\")\n",
        "print(f\"  ‚Ä¢ Training time: {training_time:.1f} seconds\")\n",
        "print(f\"  ‚Ä¢ Model performance: {final_bps:.4f} BPS\")\n",
        "print(f\"  ‚Ä¢ Memory efficiency: {final_mem_info['used_gb']:.1f} GB peak usage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion"
      },
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "You've successfully:\n",
        "\n",
        "‚úÖ **Installed CSCG-Torch** with GPU optimization  \n",
        "‚úÖ **Detected and optimized** for your specific GPU  \n",
        "‚úÖ **Generated sequences** at high speed using GPU acceleration  \n",
        "‚úÖ **Trained a CHMM model** with mixed precision and Tensor Cores  \n",
        "‚úÖ **Visualized results** and analyzed performance  \n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- üî¨ **Experiment** with different room sizes and parameters\n",
        "- üìä **Scale up** to larger sequences (1M+ steps) \n",
        "- üß† **Try different models** and training methods\n",
        "- üéØ **Custom environments** for your specific research\n",
        "\n",
        "### Resources\n",
        "\n",
        "- üìñ [Documentation](https://github.com/your-repo/cscg-torch)\n",
        "- üêõ [Report Issues](https://github.com/your-repo/cscg-torch/issues)\n",
        "- üí¨ [Discussions](https://github.com/your-repo/cscg-torch/discussions)\n",
        "\n",
        "Happy researching! üöÄ"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
